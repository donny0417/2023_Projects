{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s9MXJrakblF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54694232-75e9-45e4-c4e6-763d146d0f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터"
      ],
      "metadata": {
        "id": "odM6-mV388N4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UiqGI8FJdF5",
        "outputId": "35b2248c-657d-4f5b-a883-71702771b51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchlibrosa\n",
            "  Downloading torchlibrosa-0.1.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchlibrosa) (1.23.5)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchlibrosa) (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.0->torchlibrosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.8.0->torchlibrosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.8.0->torchlibrosa) (4.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.8.0->torchlibrosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.8.0->torchlibrosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa>=0.8.0->torchlibrosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa>=0.8.0->torchlibrosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.8.0->torchlibrosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->torchlibrosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->torchlibrosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->torchlibrosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->torchlibrosa) (2023.11.17)\n",
            "Installing collected packages: torchlibrosa\n",
            "Successfully installed torchlibrosa-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchlibrosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://os.unil.cloud.switch.ch/fma/fma_small.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TUJT8VpVddH",
        "outputId": "eaab93fd-6e63-4cd0-8738-f4433182a194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-10 04:26:00--  https://os.unil.cloud.switch.ch/fma/fma_small.zip\n",
            "Resolving os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)... 86.119.28.16, 2001:620:5ca1:201::214\n",
            "Connecting to os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)|86.119.28.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7679594875 (7.2G) [application/zip]\n",
            "Saving to: ‘fma_small.zip’\n",
            "\n",
            "fma_small.zip       100%[===================>]   7.15G  16.8MB/s    in 7m 17s  \n",
            "\n",
            "2023-12-10 04:33:19 (16.8 MB/s) - ‘fma_small.zip’ saved [7679594875/7679594875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q fma_small.zip"
      ],
      "metadata": {
        "id": "hGENNJ_CVeXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf fma_small.zip"
      ],
      "metadata": {
        "id": "ceIfpgq4fO4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf fma_small/checksums"
      ],
      "metadata": {
        "id": "5HWsLNsVf-cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf fma_small/README.txt"
      ],
      "metadata": {
        "id": "33wzHjzfgJTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "EMvSUomWom16"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-UIzqbDryGv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "drive_path = \"/content/drive/MyDrive/Colab Notebook\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsBbsUMYrbNL"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYAZnGjkLY97"
      },
      "outputs": [],
      "source": [
        "dict_label = {'Hip-Hop': 0, 'Pop': 1, 'Rock': 2, 'Folk': 3, 'Jazz': 4, 'Electronic': 5, 'Experimental': 6, 'International': 7, 'Spoken': 8, 'Country': 9, 'Blues': 10, 'Old-Time / Historic': 11, 'Soul-RnB': 12, 'Classical': 13, 'Instrumental': 14, 'Easy Listening': 15}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tracks = pd.read_csv(os.path.join(drive_path, 'tracks.csv'), index_col=0, header=[0, 1])\n",
        "\n",
        "COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
        "            ('track', 'genres'), ('track', 'genres_all')]\n",
        "for column in COLUMNS:\n",
        "    tracks[column] = tracks[column].map(ast.literal_eval)\n",
        "\n",
        "COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
        "            ('album', 'date_created'), ('album', 'date_released'),\n",
        "            ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
        "            ('artist', 'active_year_end')]\n",
        "for column in COLUMNS:\n",
        "    tracks[column] = pd.to_datetime(tracks[column])\n",
        "\n",
        "SUBSETS = ('small', 'medium', 'large')\n",
        "try:\n",
        "    tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
        "            'category', categories=SUBSETS, ordered=True)\n",
        "except (ValueError, TypeError):\n",
        "    # the categories and ordered arguments were removed in pandas 0.25\n",
        "    tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
        "                pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
        "\n",
        "COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
        "            ('album', 'type'), ('album', 'information'),\n",
        "            ('artist', 'bio')]\n",
        "for column in COLUMNS:\n",
        "    tracks[column] = tracks[column].astype('category')"
      ],
      "metadata": {
        "id": "xOLSmO_JXrzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchaudio.transforms import Resample, MelSpectrogram\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "jwbIlTJfBO44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_fft = 1024\n",
        "win_length = 1024\n",
        "hop_length = 1024\n",
        "\n",
        "n_mels = 128\n",
        "n_mfcc = 128\n",
        "\n",
        "target_sample_rate = 22040\n",
        "max_len = 1293"
      ],
      "metadata": {
        "id": "ydVcJUPmBT2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchaudio.transforms import Resample, MelSpectrogram\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "66J0iXaAJsgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "import torchaudio.transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def apply_codec(waveform, sample_rate, format, encoder=None):\n",
        "    encoder = torchaudio.io.AudioEffector(format=format, encoder=encoder)\n",
        "    return encoder.apply(waveform, sample_rate)\n",
        "\n",
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, target_sample_rate, max_len, dict_label, format, encoder=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "        self.max_len = max_len\n",
        "        self.dict_label = dict_label\n",
        "        self.format = format\n",
        "        self.encoder = encoder\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        audio_path = self.file_paths[index]\n",
        "        y, sr = librosa.load(audio_path)\n",
        "\n",
        "        # 멜 스펙트로그램 생성\n",
        "        spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=1024)\n",
        "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "        # Convert NumPy array to PyTorch tensor\n",
        "        spectrogram = torch.tensor(spectrogram)\n",
        "\n",
        "        # Ensure all spectrograms have the same length (e.g., max_len)\n",
        "        spectrogram = F.pad(spectrogram, (0, self.max_len - spectrogram.shape[1]))\n",
        "\n",
        "        spectrogram = spectrogram.unsqueeze(0)\n",
        "\n",
        "        # One-hot encode labels\n",
        "        label = F.one_hot(torch.tensor(self.labels[index]), num_classes=16).float()\n",
        "\n",
        "        return spectrogram, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)"
      ],
      "metadata": {
        "id": "xfJLg0GaMMwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/fma_small'\n",
        "\n",
        "train_data = []\n",
        "train_label = []\n",
        "val_data = []\n",
        "val_label = []\n",
        "test_data = []\n",
        "test_label = []\n",
        "err = ['001486.mp3','005574.mp3','065753.mp3','080391.mp3','098558.mp3','098559.mp3','098560.mp3','098565.mp3','098566.mp3','098567.mp3','098568.mp3','098569.mp3','098571.mp3','099134.mp3','105247.mp3','108924.mp3','108925.mp3','126981.mp3','127336.mp3','133297.mp3','143992.mp3']\n",
        "\n",
        "# Load data paths and labels (similar to your provided code)\n",
        "root = '/content/fma_small'\n",
        "\n",
        "for num in tqdm(os.listdir(root)):\n",
        "  path = os.path.join(root, num)\n",
        "  for f in os.listdir(path):\n",
        "    if f in err: continue\n",
        "\n",
        "\n",
        "for folder in tqdm(os.listdir(root)):\n",
        "  path = os.path.join(root, folder)\n",
        "  for f in os.listdir(path):\n",
        "    if f in err: continue\n",
        "    idx = int(f.split('.')[0])\n",
        "    if tracks['set', 'split'][idx] == 'training':\n",
        "      train_data.append(os.path.join(path, f))\n",
        "      train_label.append(dict_label[tracks['track', 'genre_top'][idx]])\n",
        "    elif tracks['set', 'split'][idx] == 'validation':\n",
        "      val_data.append(os.path.join(path, f))\n",
        "      val_label.append(dict_label[tracks['track', 'genre_top'][idx]])\n",
        "    elif tracks['set', 'split'][idx] == 'test':\n",
        "      test_data.append(os.path.join(path, f))\n",
        "      test_label.append(dict_label[tracks['track', 'genre_top'][idx]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzwieEoOBLmV",
        "outputId": "57f2b4d7-c04a-42d8-fea4-eb7ee8b1187d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156/156 [00:00<00:00, 9718.27it/s]\n",
            "100%|██████████| 156/156 [00:01<00:00, 103.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(SpectrogramDataset(train_data, train_label, target_sample_rate, max_len, dict_label, format, encoder=None), batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(SpectrogramDataset(val_data, val_label, target_sample_rate, max_len, dict_label, format, encoder=None), batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "IZzTh87MBIQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시로 첫 번째 배치의 데이터 shape 확인\n",
        "for batch_data, batch_labels in train_loader:\n",
        "    print(\"Batch 데이터 shape:\", batch_data.shape)\n",
        "    print(\"Batch 레이블 shape:\", batch_labels.shape)\n",
        "    break  # 첫 번째 배치만 확인하기 위해 break 문 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Zj6XNwxM7S",
        "outputId": "e82dbb8c-0453-4bf7-be69-9b4116dfda70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 데이터 shape: torch.Size([4, 1, 128, 1293])\n",
            "Batch 레이블 shape: torch.Size([4, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "MLOUC0uyXCbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50"
      ],
      "metadata": {
        "id": "h_rQ-vl3XDbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "lEwnNCVFqHph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_fft = 512\n",
        "win_length = 320\n",
        "hop_length = 320\n",
        "n_mels = 128\n",
        "# sample_rate = 192000\n",
        "model = resnet50(pretrained=False, num_classes=16)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ],
      "metadata": {
        "id": "MJCtYwleqLMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30125277-84e5-4ef8-df67-21d66b0da94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.4, patience=5, verbose=True)\n",
        "\n",
        "start_epoch = 0\n",
        "num_epochs = 50\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print_iter = 100\n",
        "save_epoch = 5\n",
        "save_iter = 1000\n",
        "test_epoch = 1"
      ],
      "metadata": {
        "id": "4P1kNU0lqSq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'FMA_ResNet50'"
      ],
      "metadata": {
        "id": "M4WWnFSeqU01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(drive_path, f\"models/{name}_checkpoint_epoch_latest.pth\")\n",
        "torch.save({\n",
        "    'epoch': start_epoch + 1,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler.state_dict': scheduler.state_dict(),\n",
        "    'loss': 0,\n",
        "}, checkpoint_path)"
      ],
      "metadata": {
        "id": "EPCOpedQqYAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "xIoEH35d_o43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading checkpoint\n",
        "checkpoint = torch.load(os.path.join(drive_path, 'models/FMA_ResNet50_checkpoint_epoch_latest.pth'))\n",
        "\n",
        "start_epoch = checkpoint['epoch'] - 1\n",
        "model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler.state_dict'])"
      ],
      "metadata": {
        "id": "pkzWLrziqTym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for iter, (inputs, labels) in enumerate(train_loader):\n",
        "        if (iter + 1) % print_iter == 1:\n",
        "              verbose_loss = 0\n",
        "              verbose_Acc = 0\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        verbose_loss += loss.item()\n",
        "\n",
        "        _, argmax = torch.max(outputs, 1)\n",
        "        _, l_argmax = torch.max(labels, 1)\n",
        "        verbose_Acc += (l_argmax == argmax).float().mean()\n",
        "\n",
        "        if (iter + 1) % print_iter == 0: print(f\"Epoch {epoch + 1}/{num_epochs}, Iteration: {iter + 1}/{len(train_loader)} Training Loss: {verbose_loss / print_iter : .4f}, Training Accuracy: {verbose_Acc / print_iter : .4f}\")\n",
        "\n",
        "        if (iter + 1) % save_iter == 0:\n",
        "          checkpoint_path = os.path.join(drive_path, f\"models/{name}_checkpoint_epoch_latest.pth\")\n",
        "          torch.save({\n",
        "              'epoch': epoch + 1,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'scheduler.state_dict': scheduler.state_dict(),\n",
        "              'loss': verbose_loss / len(train_loader),\n",
        "          }, checkpoint_path)\n",
        "\n",
        "    # Print statistics every epoch\n",
        "    #print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {loss / len(train_loader)}, Training Accuracy: {accuracy}\")\n",
        "\n",
        "    if (epoch + 1) % save_epoch == 0:\n",
        "      checkpoint_path = os.path.join(drive_path, f\"models/{name}_checkpoint_epoch_{epoch + 1}.pth\")\n",
        "      torch.save({\n",
        "          'epoch': epoch + 1,\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'scheduler.state_dict': scheduler.state_dict(),\n",
        "          'loss': verbose_loss / len(train_loader),\n",
        "      }, checkpoint_path)\n",
        "\n",
        "      print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "    # Validation\n",
        "    if (epoch + 1) % test_epoch == 0:\n",
        "      model.eval()\n",
        "      test_loss = 0.0\n",
        "      correct_predictions = 0\n",
        "      total_samples = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for inputs, labels in val_loader:\n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "              # Forward pass\n",
        "              outputs = model(inputs)\n",
        "\n",
        "              # Compute the loss for validation\n",
        "              loss = criterion(outputs, labels)\n",
        "              test_loss += loss.item()\n",
        "\n",
        "              # Calculate accuracy\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              _, labels = torch.max(labels, 1)\n",
        "\n",
        "              total_samples += labels.size(0)\n",
        "              correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "      test_loss /= len(val_loader)\n",
        "      accuracy = correct_predictions / total_samples\n",
        "\n",
        "      print(f\"Validation Loss: {test_loss}, Accuracy: {accuracy}\")\n",
        "      scheduler.step(test_loss)\n",
        "\n",
        "\n",
        "print(\"Training complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uirM-8TiqZ9l",
        "outputId": "4fa66693-49d0-4482-cd4a-e0c58cc1215a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50, Iteration: 100/1599 Training Loss:  0.0036, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 200/1599 Training Loss:  0.0022, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 300/1599 Training Loss:  0.0022, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 400/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 500/1599 Training Loss:  0.0117, Training Accuracy:  0.9950\n",
            "Epoch 29/50, Iteration: 600/1599 Training Loss:  0.0033, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 700/1599 Training Loss:  0.0092, Training Accuracy:  0.9975\n",
            "Epoch 29/50, Iteration: 800/1599 Training Loss:  0.0031, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 900/1599 Training Loss:  0.0041, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 1000/1599 Training Loss:  0.0035, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 1100/1599 Training Loss:  0.0023, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 1200/1599 Training Loss:  0.0039, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 1300/1599 Training Loss:  0.0106, Training Accuracy:  0.9975\n",
            "Epoch 29/50, Iteration: 1400/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 29/50, Iteration: 1500/1599 Training Loss:  0.0044, Training Accuracy:  0.9975\n",
            "Validation Loss: 3.7217632821386677, Accuracy: 0.50375\n",
            "Epoch 30/50, Iteration: 100/1599 Training Loss:  0.0026, Training Accuracy:  1.0000\n",
            "Epoch 30/50, Iteration: 200/1599 Training Loss:  0.0052, Training Accuracy:  0.9975\n",
            "Epoch 30/50, Iteration: 300/1599 Training Loss:  0.0026, Training Accuracy:  1.0000\n",
            "Epoch 30/50, Iteration: 400/1599 Training Loss:  0.0057, Training Accuracy:  0.9975\n",
            "Epoch 30/50, Iteration: 500/1599 Training Loss:  0.0044, Training Accuracy:  0.9975\n",
            "Epoch 30/50, Iteration: 600/1599 Training Loss:  0.0043, Training Accuracy:  1.0000\n",
            "Epoch 30/50, Iteration: 700/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 30/50, Iteration: 800/1599 Training Loss:  0.0024, Training Accuracy:  1.0000\n",
            "Epoch 30/50, Iteration: 900/1599 Training Loss:  0.0015, Training Accuracy:  1.0000\n",
            "Epoch 30/50, Iteration: 1000/1599 Training Loss:  0.0024, Training Accuracy:  1.0000\n",
            "Epoch 30/50, Iteration: 1100/1599 Training Loss:  0.0067, Training Accuracy:  0.9975\n",
            "Epoch 30/50, Iteration: 1200/1599 Training Loss:  0.0072, Training Accuracy:  0.9975\n",
            "Epoch 30/50, Iteration: 1300/1599 Training Loss:  0.0024, Training Accuracy:  1.0000\n",
            "Epoch 30/50, Iteration: 1400/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 30/50, Iteration: 1500/1599 Training Loss:  0.0090, Training Accuracy:  0.9975\n",
            "Checkpoint saved at /content/drive/MyDrive/Colab Notebook/models/FMA_ResNet50_checkpoint_epoch_30.pth\n",
            "Validation Loss: 3.7695585036249644, Accuracy: 0.49375\n",
            "Epoch 31/50, Iteration: 100/1599 Training Loss:  0.0079, Training Accuracy:  0.9950\n",
            "Epoch 31/50, Iteration: 200/1599 Training Loss:  0.0129, Training Accuracy:  0.9975\n",
            "Epoch 31/50, Iteration: 300/1599 Training Loss:  0.0043, Training Accuracy:  0.9975\n",
            "Epoch 31/50, Iteration: 400/1599 Training Loss:  0.0055, Training Accuracy:  0.9975\n",
            "Epoch 31/50, Iteration: 500/1599 Training Loss:  0.0038, Training Accuracy:  1.0000\n",
            "Epoch 31/50, Iteration: 600/1599 Training Loss:  0.0068, Training Accuracy:  0.9975\n",
            "Epoch 31/50, Iteration: 700/1599 Training Loss:  0.0028, Training Accuracy:  1.0000\n",
            "Epoch 31/50, Iteration: 800/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 31/50, Iteration: 900/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 31/50, Iteration: 1000/1599 Training Loss:  0.0019, Training Accuracy:  1.0000\n",
            "Epoch 31/50, Iteration: 1100/1599 Training Loss:  0.0089, Training Accuracy:  0.9975\n",
            "Epoch 31/50, Iteration: 1200/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 31/50, Iteration: 1300/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 31/50, Iteration: 1400/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 31/50, Iteration: 1500/1599 Training Loss:  0.0044, Training Accuracy:  0.9975\n",
            "Validation Loss: 3.783567484335149, Accuracy: 0.4975\n",
            "Epoch 32/50, Iteration: 100/1599 Training Loss:  0.0037, Training Accuracy:  0.9975\n",
            "Epoch 32/50, Iteration: 200/1599 Training Loss:  0.0075, Training Accuracy:  0.9975\n",
            "Epoch 32/50, Iteration: 300/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 32/50, Iteration: 400/1599 Training Loss:  0.0022, Training Accuracy:  1.0000\n",
            "Epoch 32/50, Iteration: 500/1599 Training Loss:  0.0030, Training Accuracy:  1.0000\n",
            "Epoch 32/50, Iteration: 600/1599 Training Loss:  0.0027, Training Accuracy:  1.0000\n",
            "Epoch 32/50, Iteration: 700/1599 Training Loss:  0.0029, Training Accuracy:  1.0000\n",
            "Epoch 32/50, Iteration: 800/1599 Training Loss:  0.0158, Training Accuracy:  0.9975\n",
            "Epoch 32/50, Iteration: 900/1599 Training Loss:  0.0010, Training Accuracy:  1.0000\n",
            "Epoch 32/50, Iteration: 1000/1599 Training Loss:  0.0139, Training Accuracy:  0.9950\n",
            "Epoch 32/50, Iteration: 1100/1599 Training Loss:  0.0039, Training Accuracy:  0.9975\n",
            "Epoch 32/50, Iteration: 1200/1599 Training Loss:  0.0042, Training Accuracy:  1.0000\n",
            "Epoch 32/50, Iteration: 1300/1599 Training Loss:  0.0046, Training Accuracy:  0.9975\n",
            "Epoch 32/50, Iteration: 1400/1599 Training Loss:  0.0104, Training Accuracy:  0.9975\n",
            "Epoch 32/50, Iteration: 1500/1599 Training Loss:  0.0011, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.836160428246694, Accuracy: 0.49125\n",
            "Epoch 33/50, Iteration: 100/1599 Training Loss:  0.0054, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 200/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 300/1599 Training Loss:  0.0068, Training Accuracy:  0.9975\n",
            "Epoch 33/50, Iteration: 400/1599 Training Loss:  0.0019, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 500/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 600/1599 Training Loss:  0.0010, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 700/1599 Training Loss:  0.0071, Training Accuracy:  0.9975\n",
            "Epoch 33/50, Iteration: 800/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 900/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 1000/1599 Training Loss:  0.0092, Training Accuracy:  0.9975\n",
            "Epoch 33/50, Iteration: 1100/1599 Training Loss:  0.0034, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 1200/1599 Training Loss:  0.0067, Training Accuracy:  0.9975\n",
            "Epoch 33/50, Iteration: 1300/1599 Training Loss:  0.0029, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 1400/1599 Training Loss:  0.0022, Training Accuracy:  1.0000\n",
            "Epoch 33/50, Iteration: 1500/1599 Training Loss:  0.0026, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.8030682128745625, Accuracy: 0.49125\n",
            "Epoch 34/50, Iteration: 100/1599 Training Loss:  0.0024, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 200/1599 Training Loss:  0.0103, Training Accuracy:  0.9950\n",
            "Epoch 34/50, Iteration: 300/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 400/1599 Training Loss:  0.0041, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 500/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 600/1599 Training Loss:  0.0032, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 700/1599 Training Loss:  0.0168, Training Accuracy:  0.9950\n",
            "Epoch 34/50, Iteration: 800/1599 Training Loss:  0.0044, Training Accuracy:  0.9975\n",
            "Epoch 34/50, Iteration: 900/1599 Training Loss:  0.0023, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 1000/1599 Training Loss:  0.0011, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 1100/1599 Training Loss:  0.0025, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 1200/1599 Training Loss:  0.0079, Training Accuracy:  0.9975\n",
            "Epoch 34/50, Iteration: 1300/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 1400/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 34/50, Iteration: 1500/1599 Training Loss:  0.0172, Training Accuracy:  0.9975\n",
            "Validation Loss: 3.712628810235725, Accuracy: 0.49\n",
            "Epoch 00034: reducing learning rate of group 0 to 1.0240e-06.\n",
            "Epoch 35/50, Iteration: 100/1599 Training Loss:  0.0033, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 200/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 300/1599 Training Loss:  0.0009, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 400/1599 Training Loss:  0.0094, Training Accuracy:  0.9950\n",
            "Epoch 35/50, Iteration: 500/1599 Training Loss:  0.0034, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 600/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 700/1599 Training Loss:  0.0094, Training Accuracy:  0.9975\n",
            "Epoch 35/50, Iteration: 800/1599 Training Loss:  0.0025, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 900/1599 Training Loss:  0.0077, Training Accuracy:  0.9975\n",
            "Epoch 35/50, Iteration: 1000/1599 Training Loss:  0.0039, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 1100/1599 Training Loss:  0.0023, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 1200/1599 Training Loss:  0.0075, Training Accuracy:  0.9975\n",
            "Epoch 35/50, Iteration: 1300/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 1400/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 35/50, Iteration: 1500/1599 Training Loss:  0.0104, Training Accuracy:  0.9975\n",
            "Checkpoint saved at /content/drive/MyDrive/Colab Notebook/models/FMA_ResNet50_checkpoint_epoch_35.pth\n",
            "Validation Loss: 3.675662196809344, Accuracy: 0.48875\n",
            "Epoch 36/50, Iteration: 100/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 36/50, Iteration: 200/1599 Training Loss:  0.0032, Training Accuracy:  0.9975\n",
            "Epoch 36/50, Iteration: 300/1599 Training Loss:  0.0022, Training Accuracy:  1.0000\n",
            "Epoch 36/50, Iteration: 400/1599 Training Loss:  0.0036, Training Accuracy:  0.9975\n",
            "Epoch 36/50, Iteration: 500/1599 Training Loss:  0.0065, Training Accuracy:  0.9975\n",
            "Epoch 36/50, Iteration: 600/1599 Training Loss:  0.0029, Training Accuracy:  1.0000\n",
            "Epoch 36/50, Iteration: 700/1599 Training Loss:  0.0049, Training Accuracy:  0.9975\n",
            "Epoch 36/50, Iteration: 800/1599 Training Loss:  0.0015, Training Accuracy:  1.0000\n",
            "Epoch 36/50, Iteration: 900/1599 Training Loss:  0.0028, Training Accuracy:  1.0000\n",
            "Epoch 36/50, Iteration: 1000/1599 Training Loss:  0.0056, Training Accuracy:  0.9975\n",
            "Epoch 36/50, Iteration: 1100/1599 Training Loss:  0.0064, Training Accuracy:  0.9975\n",
            "Epoch 36/50, Iteration: 1200/1599 Training Loss:  0.0028, Training Accuracy:  1.0000\n",
            "Epoch 36/50, Iteration: 1300/1599 Training Loss:  0.0043, Training Accuracy:  1.0000\n",
            "Epoch 36/50, Iteration: 1400/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 36/50, Iteration: 1500/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.732248944401176, Accuracy: 0.48625\n",
            "Epoch 37/50, Iteration: 100/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 37/50, Iteration: 200/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 37/50, Iteration: 300/1599 Training Loss:  0.0033, Training Accuracy:  1.0000\n",
            "Epoch 37/50, Iteration: 400/1599 Training Loss:  0.0084, Training Accuracy:  0.9950\n",
            "Epoch 37/50, Iteration: 500/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 37/50, Iteration: 600/1599 Training Loss:  0.0037, Training Accuracy:  1.0000\n",
            "Epoch 37/50, Iteration: 700/1599 Training Loss:  0.0015, Training Accuracy:  1.0000\n",
            "Epoch 37/50, Iteration: 800/1599 Training Loss:  0.0026, Training Accuracy:  1.0000\n",
            "Epoch 37/50, Iteration: 900/1599 Training Loss:  0.0045, Training Accuracy:  0.9975\n",
            "Epoch 37/50, Iteration: 1000/1599 Training Loss:  0.0059, Training Accuracy:  0.9975\n",
            "Epoch 37/50, Iteration: 1100/1599 Training Loss:  0.0035, Training Accuracy:  1.0000\n",
            "Epoch 37/50, Iteration: 1200/1599 Training Loss:  0.0035, Training Accuracy:  0.9975\n",
            "Epoch 37/50, Iteration: 1300/1599 Training Loss:  0.0025, Training Accuracy:  1.0000\n",
            "Epoch 37/50, Iteration: 1400/1599 Training Loss:  0.0069, Training Accuracy:  0.9950\n",
            "Epoch 37/50, Iteration: 1500/1599 Training Loss:  0.0031, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.7635826930656116, Accuracy: 0.4825\n",
            "Epoch 38/50, Iteration: 100/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 200/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 300/1599 Training Loss:  0.0009, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 400/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 500/1599 Training Loss:  0.0037, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 600/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 700/1599 Training Loss:  0.0155, Training Accuracy:  0.9975\n",
            "Epoch 38/50, Iteration: 800/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 900/1599 Training Loss:  0.0023, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 1000/1599 Training Loss:  0.0036, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 1100/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 1200/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 1300/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 1400/1599 Training Loss:  0.0011, Training Accuracy:  1.0000\n",
            "Epoch 38/50, Iteration: 1500/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.7760423398854392, Accuracy: 0.495\n",
            "Epoch 39/50, Iteration: 100/1599 Training Loss:  0.0023, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 200/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 300/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 400/1599 Training Loss:  0.0025, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 500/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 600/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 700/1599 Training Loss:  0.0007, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 800/1599 Training Loss:  0.0042, Training Accuracy:  0.9975\n",
            "Epoch 39/50, Iteration: 900/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 1000/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 1100/1599 Training Loss:  0.0111, Training Accuracy:  0.9950\n",
            "Epoch 39/50, Iteration: 1200/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 1300/1599 Training Loss:  0.0026, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 1400/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 39/50, Iteration: 1500/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.8286941038571376, Accuracy: 0.485\n",
            "Epoch 40/50, Iteration: 100/1599 Training Loss:  0.0029, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 200/1599 Training Loss:  0.0046, Training Accuracy:  0.9975\n",
            "Epoch 40/50, Iteration: 300/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 400/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 500/1599 Training Loss:  0.0072, Training Accuracy:  0.9975\n",
            "Epoch 40/50, Iteration: 600/1599 Training Loss:  0.0121, Training Accuracy:  0.9950\n",
            "Epoch 40/50, Iteration: 700/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 800/1599 Training Loss:  0.0029, Training Accuracy:  0.9975\n",
            "Epoch 40/50, Iteration: 900/1599 Training Loss:  0.0008, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 1000/1599 Training Loss:  0.0015, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 1100/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 1200/1599 Training Loss:  0.0007, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 1300/1599 Training Loss:  0.0028, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 1400/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 40/50, Iteration: 1500/1599 Training Loss:  0.0019, Training Accuracy:  1.0000\n",
            "Checkpoint saved at /content/drive/MyDrive/Colab Notebook/models/FMA_ResNet50_checkpoint_epoch_40.pth\n",
            "Validation Loss: 3.711449367993632, Accuracy: 0.4975\n",
            "Epoch 00040: reducing learning rate of group 0 to 4.0960e-07.\n",
            "Epoch 41/50, Iteration: 100/1599 Training Loss:  0.0024, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 200/1599 Training Loss:  0.0009, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 300/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 400/1599 Training Loss:  0.0010, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 500/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 600/1599 Training Loss:  0.0081, Training Accuracy:  0.9950\n",
            "Epoch 41/50, Iteration: 700/1599 Training Loss:  0.0025, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 800/1599 Training Loss:  0.0100, Training Accuracy:  0.9975\n",
            "Epoch 41/50, Iteration: 900/1599 Training Loss:  0.0027, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 1000/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 1100/1599 Training Loss:  0.0010, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 1200/1599 Training Loss:  0.0015, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 1300/1599 Training Loss:  0.0060, Training Accuracy:  0.9975\n",
            "Epoch 41/50, Iteration: 1400/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 41/50, Iteration: 1500/1599 Training Loss:  0.0031, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.860006954592684, Accuracy: 0.5\n",
            "Epoch 42/50, Iteration: 100/1599 Training Loss:  0.0007, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 200/1599 Training Loss:  0.0011, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 300/1599 Training Loss:  0.0007, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 400/1599 Training Loss:  0.0008, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 500/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 600/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 700/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 800/1599 Training Loss:  0.0026, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 900/1599 Training Loss:  0.0023, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 1000/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 1100/1599 Training Loss:  0.0022, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 1200/1599 Training Loss:  0.0264, Training Accuracy:  0.9950\n",
            "Epoch 42/50, Iteration: 1300/1599 Training Loss:  0.0097, Training Accuracy:  0.9950\n",
            "Epoch 42/50, Iteration: 1400/1599 Training Loss:  0.0008, Training Accuracy:  1.0000\n",
            "Epoch 42/50, Iteration: 1500/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.7972735486029205, Accuracy: 0.49625\n",
            "Epoch 43/50, Iteration: 100/1599 Training Loss:  0.0045, Training Accuracy:  0.9975\n",
            "Epoch 43/50, Iteration: 200/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 300/1599 Training Loss:  0.0007, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 400/1599 Training Loss:  0.0030, Training Accuracy:  0.9975\n",
            "Epoch 43/50, Iteration: 500/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 600/1599 Training Loss:  0.0034, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 700/1599 Training Loss:  0.0029, Training Accuracy:  0.9975\n",
            "Epoch 43/50, Iteration: 800/1599 Training Loss:  0.0009, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 900/1599 Training Loss:  0.0024, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 1000/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 1100/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 1200/1599 Training Loss:  0.0025, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 1300/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 1400/1599 Training Loss:  0.0025, Training Accuracy:  1.0000\n",
            "Epoch 43/50, Iteration: 1500/1599 Training Loss:  0.0027, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.8443879677539736, Accuracy: 0.48875\n",
            "Epoch 44/50, Iteration: 100/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 200/1599 Training Loss:  0.0087, Training Accuracy:  0.9975\n",
            "Epoch 44/50, Iteration: 300/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 400/1599 Training Loss:  0.0006, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 500/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 600/1599 Training Loss:  0.0029, Training Accuracy:  0.9975\n",
            "Epoch 44/50, Iteration: 700/1599 Training Loss:  0.0085, Training Accuracy:  0.9975\n",
            "Epoch 44/50, Iteration: 800/1599 Training Loss:  0.0006, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 900/1599 Training Loss:  0.0026, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 1000/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 1100/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 1200/1599 Training Loss:  0.0015, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 1300/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 1400/1599 Training Loss:  0.0026, Training Accuracy:  1.0000\n",
            "Epoch 44/50, Iteration: 1500/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.7704348393176086, Accuracy: 0.4975\n",
            "Epoch 45/50, Iteration: 100/1599 Training Loss:  0.0052, Training Accuracy:  0.9975\n",
            "Epoch 45/50, Iteration: 200/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 45/50, Iteration: 300/1599 Training Loss:  0.0019, Training Accuracy:  1.0000\n",
            "Epoch 45/50, Iteration: 400/1599 Training Loss:  0.0045, Training Accuracy:  0.9975\n",
            "Epoch 45/50, Iteration: 500/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 45/50, Iteration: 600/1599 Training Loss:  0.0045, Training Accuracy:  0.9975\n",
            "Epoch 45/50, Iteration: 700/1599 Training Loss:  0.0052, Training Accuracy:  0.9975\n",
            "Epoch 45/50, Iteration: 800/1599 Training Loss:  0.0063, Training Accuracy:  0.9975\n",
            "Epoch 45/50, Iteration: 900/1599 Training Loss:  0.0011, Training Accuracy:  1.0000\n",
            "Epoch 45/50, Iteration: 1000/1599 Training Loss:  0.0010, Training Accuracy:  1.0000\n",
            "Epoch 45/50, Iteration: 1100/1599 Training Loss:  0.0019, Training Accuracy:  1.0000\n",
            "Epoch 45/50, Iteration: 1200/1599 Training Loss:  0.0029, Training Accuracy:  1.0000\n",
            "Epoch 45/50, Iteration: 1300/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 45/50, Iteration: 1400/1599 Training Loss:  0.0019, Training Accuracy:  1.0000\n",
            "Epoch 45/50, Iteration: 1500/1599 Training Loss:  0.0011, Training Accuracy:  1.0000\n",
            "Checkpoint saved at /content/drive/MyDrive/Colab Notebook/models/FMA_ResNet50_checkpoint_epoch_45.pth\n",
            "Validation Loss: 3.7372766059832405, Accuracy: 0.49125\n",
            "Epoch 46/50, Iteration: 100/1599 Training Loss:  0.0035, Training Accuracy:  0.9975\n",
            "Epoch 46/50, Iteration: 200/1599 Training Loss:  0.0056, Training Accuracy:  0.9950\n",
            "Epoch 46/50, Iteration: 300/1599 Training Loss:  0.0036, Training Accuracy:  1.0000\n",
            "Epoch 46/50, Iteration: 400/1599 Training Loss:  0.0100, Training Accuracy:  0.9925\n",
            "Epoch 46/50, Iteration: 500/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 46/50, Iteration: 600/1599 Training Loss:  0.0031, Training Accuracy:  0.9975\n",
            "Epoch 46/50, Iteration: 700/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 46/50, Iteration: 800/1599 Training Loss:  0.0042, Training Accuracy:  0.9975\n",
            "Epoch 46/50, Iteration: 900/1599 Training Loss:  0.0009, Training Accuracy:  1.0000\n",
            "Epoch 46/50, Iteration: 1000/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 46/50, Iteration: 1100/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 46/50, Iteration: 1200/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 46/50, Iteration: 1300/1599 Training Loss:  0.0028, Training Accuracy:  1.0000\n",
            "Epoch 46/50, Iteration: 1400/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 46/50, Iteration: 1500/1599 Training Loss:  0.0019, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.747954041258906, Accuracy: 0.49625\n",
            "Epoch 00046: reducing learning rate of group 0 to 1.6384e-07.\n",
            "Epoch 47/50, Iteration: 100/1599 Training Loss:  0.0039, Training Accuracy:  0.9975\n",
            "Epoch 47/50, Iteration: 200/1599 Training Loss:  0.0015, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 300/1599 Training Loss:  0.0022, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 400/1599 Training Loss:  0.0027, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 500/1599 Training Loss:  0.0019, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 600/1599 Training Loss:  0.0008, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 700/1599 Training Loss:  0.0176, Training Accuracy:  0.9950\n",
            "Epoch 47/50, Iteration: 800/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 900/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 1000/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 1100/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 1200/1599 Training Loss:  0.0022, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 1300/1599 Training Loss:  0.0038, Training Accuracy:  0.9975\n",
            "Epoch 47/50, Iteration: 1400/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 47/50, Iteration: 1500/1599 Training Loss:  0.0022, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.8604988892012897, Accuracy: 0.49625\n",
            "Epoch 48/50, Iteration: 100/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 200/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 300/1599 Training Loss:  0.0056, Training Accuracy:  0.9975\n",
            "Epoch 48/50, Iteration: 400/1599 Training Loss:  0.0024, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 500/1599 Training Loss:  0.0077, Training Accuracy:  0.9975\n",
            "Epoch 48/50, Iteration: 600/1599 Training Loss:  0.0013, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 700/1599 Training Loss:  0.0023, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 800/1599 Training Loss:  0.0025, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 900/1599 Training Loss:  0.0037, Training Accuracy:  0.9975\n",
            "Epoch 48/50, Iteration: 1000/1599 Training Loss:  0.0059, Training Accuracy:  0.9975\n",
            "Epoch 48/50, Iteration: 1100/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 1200/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 1300/1599 Training Loss:  0.0011, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 1400/1599 Training Loss:  0.0020, Training Accuracy:  1.0000\n",
            "Epoch 48/50, Iteration: 1500/1599 Training Loss:  0.0086, Training Accuracy:  0.9975\n",
            "Validation Loss: 3.8258312507042502, Accuracy: 0.49125\n",
            "Epoch 49/50, Iteration: 100/1599 Training Loss:  0.0014, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 200/1599 Training Loss:  0.0018, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 300/1599 Training Loss:  0.0042, Training Accuracy:  0.9975\n",
            "Epoch 49/50, Iteration: 400/1599 Training Loss:  0.0015, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 500/1599 Training Loss:  0.0006, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 600/1599 Training Loss:  0.0006, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 700/1599 Training Loss:  0.0028, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 800/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 900/1599 Training Loss:  0.0016, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 1000/1599 Training Loss:  0.0026, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 1100/1599 Training Loss:  0.0011, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 1200/1599 Training Loss:  0.0009, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 1300/1599 Training Loss:  0.0007, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 1400/1599 Training Loss:  0.0010, Training Accuracy:  1.0000\n",
            "Epoch 49/50, Iteration: 1500/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Validation Loss: 3.778242411841611, Accuracy: 0.49125\n",
            "Epoch 50/50, Iteration: 100/1599 Training Loss:  0.0017, Training Accuracy:  1.0000\n",
            "Epoch 50/50, Iteration: 200/1599 Training Loss:  0.0088, Training Accuracy:  0.9950\n",
            "Epoch 50/50, Iteration: 300/1599 Training Loss:  0.0024, Training Accuracy:  1.0000\n",
            "Epoch 50/50, Iteration: 400/1599 Training Loss:  0.0024, Training Accuracy:  1.0000\n",
            "Epoch 50/50, Iteration: 500/1599 Training Loss:  0.0031, Training Accuracy:  1.0000\n",
            "Epoch 50/50, Iteration: 600/1599 Training Loss:  0.0012, Training Accuracy:  1.0000\n",
            "Epoch 50/50, Iteration: 700/1599 Training Loss:  0.0021, Training Accuracy:  1.0000\n",
            "Epoch 50/50, Iteration: 800/1599 Training Loss:  0.0049, Training Accuracy:  0.9975\n",
            "Epoch 50/50, Iteration: 900/1599 Training Loss:  0.0023, Training Accuracy:  1.0000\n",
            "Epoch 50/50, Iteration: 1000/1599 Training Loss:  0.0034, Training Accuracy:  0.9975\n",
            "Epoch 50/50, Iteration: 1100/1599 Training Loss:  0.0065, Training Accuracy:  0.9975\n",
            "Epoch 50/50, Iteration: 1200/1599 Training Loss:  0.0027, Training Accuracy:  1.0000\n",
            "Epoch 50/50, Iteration: 1300/1599 Training Loss:  0.0031, Training Accuracy:  1.0000\n",
            "Epoch 50/50, Iteration: 1400/1599 Training Loss:  0.0080, Training Accuracy:  0.9950\n",
            "Epoch 50/50, Iteration: 1500/1599 Training Loss:  0.0032, Training Accuracy:  0.9975\n",
            "Checkpoint saved at /content/drive/MyDrive/Colab Notebook/models/FMA_ResNet50_checkpoint_epoch_50.pth\n",
            "Validation Loss: 3.811450369729059, Accuracy: 0.48625\n",
            "Training complete\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "odM6-mV388N4",
        "EMvSUomWom16",
        "p32kFqIk9_MN"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}